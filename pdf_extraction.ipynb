{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529f34de-a69b-4825-87d8-f7b6a54bc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New notebook cell - PDF processing\n",
    "import requests\n",
    "import PyPDF2\n",
    "import openai\n",
    "from io import BytesIO\n",
    "\n",
    "def extract_text_from_pdf_url(pdf_url):\n",
    "    \"\"\"Download PDF and extract text\"\"\"\n",
    "    # Download PDF\n",
    "    response = requests.get(pdf_url)\n",
    "    \n",
    "    # Read PDF content\n",
    "    pdf_file = BytesIO(response.content)\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, overlap=200):\n",
    "    \"\"\"Split text into overlapping chunks\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # Overlap for continuity\n",
    "    \n",
    "    return chunks\n",
    "    \n",
    "def process_article_fully(article_id):\n",
    "    \"\"\"Take an article from metadata_only to fully_processed\"\"\"\n",
    "    # 1. Get article info\n",
    "    article = supabase.table('articles').select('*').eq('id', article_id).execute()\n",
    "    article = article.data[0]\n",
    "    \n",
    "    # 2. Extract PDF text\n",
    "    text = extract_text_from_pdf_url(article['pdf_url'])\n",
    "    \n",
    "    # 3. Chunk text\n",
    "    chunks = chunk_text(text)\n",
    "    \n",
    "    # 4. Process each chunk\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Generate embedding\n",
    "        embedding = openai.Embedding.create(\n",
    "            input=chunk,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )['data'][0]['embedding']\n",
    "        \n",
    "        # Store chunk\n",
    "        chunk_data = {\n",
    "            'article_id': article_id,\n",
    "            'chunk_text': chunk,\n",
    "            'chunk_index': i,\n",
    "            'embedding': embedding\n",
    "        }\n",
    "        supabase.table('article_chunks').insert(chunk_data).execute()\n",
    "    \n",
    "    # 5. Update article status\n",
    "    supabase.table('articles').update({'processing_status': 'fully_processed'}).eq('id', article_id).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e674da3c-0460-4afd-b5a4-0e0822a7032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_url = \"https://arxiv.org/pdf/1905.11833\"\n",
    "x = extract_text_from_pdf_url(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9987780-3c85-4314-a0dd-f31555eaed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61036"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f58b95-52cc-403d-a0a7-b2bd86b5df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interpreting and improving natural-language\\nprocessing (in machines) with natural\\nlanguage-processing (in the brain)\\nMariya Toneva\\nNeuroscience Instit'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:150].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d717aa9e-b0ca-4b22-8c02-b8423b9fe319",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = chunk_text(x[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a64ca5-f58c-4132-9a66-ab48b8752118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eef50dc-6de3-426b-bcf1-d98717e854d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Interpreting and improving natural-language\\nprocessing (in machines) with natural\\nlanguage-processing (in the brain)\\nMariya Toneva\\nNeuroscience Institute\\nDepartment of Machine Learning\\nCarnegie Mellon University\\nmariya@cmu.eduLeila Wehbe\\nNeuroscience Institute\\nDepartment of Machine Learning\\nCarnegie Mellon University\\nlwehbe@cmu.edu\\nAbstract\\nNeural networks models for NLP are typically implemented without the explicit\\nencoding of language rules and yet they are able to break one performance record\\nafter another. This has generated a lot of research interest in interpreting the\\nrepresentations learned by these networks. We propose here a novel interpretation\\napproach that relies on the only processing system we have that does understand\\nlanguage: the human brain. We use brain imaging recordings of subjects reading\\ncomplex natural text to interpret word and sequence embeddings from 4recent\\nNLP models - ELMo, USE, BERT and Transformer-XL. We study how their\\nrepresentations differ across la',\n",
       " '...',\n",
       " '...',\n",
       " 'ngs of subjects reading\\ncomplex natural text to interpret word and sequence embeddings from 4recent\\nNLP models - ELMo, USE, BERT and Transformer-XL. We study how their\\nrepresentations differ across layer depth, context length, and attention type. Our\\nresults reveal differences in the context-related representations across these models.\\nFurther, in the transformer models, we ï¬nd an interaction between layer depth and\\ncontext length, and between layer depth and attention type. We ï¬nally hypothesize\\nthat altering BERT to better align with brain recordings would enable it to also\\nbetter understand language. Probing the altered BERT using syntactic NLP tasks\\nreveals that the model with increased ')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], \"...\", \"...\", y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6982f03-1e67-409c-a852-5595f837c3c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIRemovedInV1\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embedding = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-embedding-ada-002\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Code\\ai-research-tracking\\.venv\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[39m, in \u001b[36mAPIRemovedInV1Proxy.__call__\u001b[39m\u001b[34m(self, *_args, **_kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *_args: Any, **_kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol=\u001b[38;5;28mself\u001b[39m._symbol)\n",
      "\u001b[31mAPIRemovedInV1\u001b[39m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "embedding = openai.Embedding.create(input=y[0], model=\"text-embedding-ada-002\")['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e2a6298-0f61-4512-8886-2208dd5aa840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generated embedding with 1536 dimensions\n",
      "First 5 values: [-0.025302225723862648, -0.0005367214907892048, -0.0003945132193621248, 0.0063355653546750546, -0.0010434165596961975]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Test with your chunk\n",
    "def generate_embedding(text):\n",
    "    \"\"\"Generate embedding using new OpenAI API\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Test it\n",
    "test_text = \"This is a test sentence for embedding generation.\"\n",
    "embedding = generate_embedding(test_text)\n",
    "\n",
    "print(f\"âœ… Generated embedding with {len(embedding)} dimensions\")\n",
    "print(f\"First 5 values: {embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa7a225-93c6-440a-85ab-db9defbd9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def generate_embedding(text):\n",
    "    \"\"\"Generate embedding using OpenAI\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54ac8df-5f6d-40aa-b341-87387e6069db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generate_embedding(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f02813-abb1-4e89-8478-c65931184d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03363104164600372,\n",
       " 0.009249209426343441,\n",
       " 0.023493262007832527,\n",
       " -0.03346948325634003,\n",
       " 0.00556029612198472,\n",
       " 0.012776564806699753,\n",
       " 0.010097390040755272,\n",
       " 0.01740790158510208,\n",
       " -0.02598395198583603,\n",
       " -0.04103579372167587]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6590ce9f-40db-4267-97a9-272237cfd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting a paper to process...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'supabase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Test with one of your saved papers\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGetting a paper to process...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m result = \u001b[43msupabase\u001b[49m.table(\u001b[33m'\u001b[39m\u001b[33marticles\u001b[39m\u001b[33m'\u001b[39m)\\\n\u001b[32m    103\u001b[39m     .select(\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m)\\\n\u001b[32m    104\u001b[39m     .eq(\u001b[33m'\u001b[39m\u001b[33mprocessing_status\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmetadata_only\u001b[39m\u001b[33m'\u001b[39m)\\\n\u001b[32m    105\u001b[39m     .limit(\u001b[32m1\u001b[39m)\\\n\u001b[32m    106\u001b[39m     .execute()\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.data:\n\u001b[32m    109\u001b[39m     paper = result.data[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'supabase' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def extract_text_from_pdf_url(pdf_url):\n",
    "    \"\"\"Download PDF and extract text\"\"\"\n",
    "    print(f\"Downloading PDF from: {pdf_url}\")\n",
    "    response = requests.get(pdf_url)\n",
    "    \n",
    "    pdf_file = BytesIO(response.content)\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    \n",
    "    text = \"\"\n",
    "    for page_num, page in enumerate(pdf_reader.pages):\n",
    "        text += page.extract_text()\n",
    "        print(f\"  Extracted page {page_num + 1}/{len(pdf_reader.pages)}\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, overlap=200):\n",
    "    \"\"\"Split text into overlapping chunks\"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def generate_embedding(text):\n",
    "    \"\"\"Generate embedding using OpenAI\"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def process_article_fully(article_id):\n",
    "    \"\"\"Process an article: extract PDF, chunk, embed, store\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing article: {article_id}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # 1. Get article from database\n",
    "    result = supabase.table('articles').select('*').eq('id', article_id).execute()\n",
    "    if not result.data:\n",
    "        print(\"âŒ Article not found\")\n",
    "        return\n",
    "    \n",
    "    article = result.data[0]\n",
    "    print(f\"ðŸ“„ Title: {article['title']}\")\n",
    "    \n",
    "    # 2. Extract text from PDF\n",
    "    print(\"\\nðŸ“¥ Extracting PDF text...\")\n",
    "    text = extract_text_from_pdf_url(article['pdf_url'])\n",
    "    print(f\"âœ… Extracted {len(text)} characters\")\n",
    "    \n",
    "    # 3. Chunk the text\n",
    "    print(\"\\nâœ‚ï¸  Chunking text...\")\n",
    "    chunks = chunk_text(text, chunk_size=1000, overlap=200)\n",
    "    print(f\"âœ… Created {len(chunks)} chunks\")\n",
    "    \n",
    "    # 4. Process each chunk\n",
    "    print(\"\\nðŸ”„ Generating embeddings and storing chunks...\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"  Processing chunk {i+1}/{len(chunks)}...\", end='\\r')\n",
    "        \n",
    "        # Generate embedding\n",
    "        embedding = generate_embedding(chunk)\n",
    "        \n",
    "        # Store in database\n",
    "        chunk_data = {\n",
    "            'article_id': article_id,\n",
    "            'chunk_text': chunk,\n",
    "            'chunk_index': i,\n",
    "            'embedding': embedding\n",
    "        }\n",
    "        \n",
    "        supabase.table('article_chunks').insert(chunk_data).execute()\n",
    "    \n",
    "    print(f\"\\nâœ… Stored {len(chunks)} chunks\")\n",
    "    \n",
    "    # 5. Update article status\n",
    "    print(\"\\nðŸ“ Updating article status...\")\n",
    "    supabase.table('articles')\\\n",
    "        .update({'processing_status': 'fully_processed'})\\\n",
    "        .eq('id', article_id)\\\n",
    "        .execute()\n",
    "    \n",
    "    print(\"âœ… Article fully processed!\")\n",
    "    return len(chunks)\n",
    "\n",
    "# Test with one of your saved papers\n",
    "print(\"Getting a paper to process...\")\n",
    "result = supabase.table('articles')\\\n",
    "    .select('*')\\\n",
    "    .eq('processing_status', 'metadata_only')\\\n",
    "    .limit(1)\\\n",
    "    .execute()\n",
    "\n",
    "if result.data:\n",
    "    paper = result.data[0]\n",
    "    print(f\"Found paper: {paper['title'][:60]}...\")\n",
    "    \n",
    "    # Process it\n",
    "    num_chunks = process_article_fully(paper['id'])\n",
    "    \n",
    "    # Verify chunks were stored\n",
    "    chunks_result = supabase.table('article_chunks')\\\n",
    "        .select('*')\\\n",
    "        .eq('article_id', paper['id'])\\\n",
    "        .execute()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Verification: {len(chunks_result.data)} chunks in database\")\n",
    "else:\n",
    "    print(\"No unprocessed papers found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc486e-c344-4cde-b748-9703a1145133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
