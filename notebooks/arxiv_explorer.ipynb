{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a75382f-5c3d-4ef1-a795-89bde7a8b3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "Current time: 2025-09-20 14:28:04.504664\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import requests\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime, timedelta\n",
    "import arxiv\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"Current time: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344beeef-017f-4f72-83e8-688f501cd61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making request to arXiv API...\n",
      "URL: http://export.arxiv.org/api/query\n",
      "Parameters: {'search_query': 'cat:cs.AI', 'start': 0, 'max_results': 3, 'sortBy': 'submittedDate', 'sortOrder': 'descending'}\n",
      "\n",
      "Response status: 200\n",
      "Response headers: {'Connection': 'keep-alive', 'Content-Length': '2906', 'content-encoding': 'gzip', 'server': 'Apache', 'content-type': 'application/atom+xml; charset=UTF-8', 'via': '1.1 varnish, 1.1 varnish, 1.1 varnish', 'access-control-allow-origin': '*', 'Accept-Ranges': 'bytes', 'Age': '0', 'Date': 'Sat, 20 Sep 2025 13:28:29 GMT', 'X-Served-By': 'cache-lga21958-LGA, cache-lga21971-LGA, cache-man4136-MAN', 'X-Cache': 'MISS, MISS, MISS', 'X-Cache-Hits': '0, 0, 0', 'X-Timer': 'S1758374909.921910,VS0,VE276', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=300'}\n",
      "Response length: 8883 bytes\n"
     ]
    }
   ],
   "source": [
    "# Make a raw HTTP request to arXiv API first\n",
    "base_url = \"http://export.arxiv.org/api/query\"\n",
    "\n",
    "# Simple search for AI papers\n",
    "params = {\n",
    "    'search_query': 'cat:cs.AI',\n",
    "    'start': 0,\n",
    "    'max_results': 3,\n",
    "    'sortBy': 'submittedDate',\n",
    "    'sortOrder': 'descending'\n",
    "}\n",
    "\n",
    "print(\"Making request to arXiv API...\")\n",
    "print(f\"URL: {base_url}\")\n",
    "print(f\"Parameters: {params}\")\n",
    "\n",
    "response = requests.get(base_url, params=params)\n",
    "\n",
    "print(f\"\\nResponse status: {response.status_code}\")\n",
    "print(f\"Response headers: {dict(response.headers)}\")\n",
    "print(f\"Response length: {len(response.content)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5469753f-40f2-43e3-97aa-41aa0b72ac7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw XML response (first 1000 characters):\n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <link href=\"http://arxiv.org/api/query?search_query%3Dcat%3Acs.AI%26id_list%3D%26start%3D0%26max_results%3D3\" rel=\"self\" type=\"application/atom+xml\"/>\n",
      "  <title type=\"html\">ArXiv Query: search_query=cat:cs.AI&amp;id_list=&amp;start=0&amp;max_results=3</title>\n",
      "  <id>http://arxiv.org/api/R0SPnx8l8tIxrHMPwcpdin6AZn8</id>\n",
      "  <updated>2025-09-20T00:00:00-04:00</updated>\n",
      "  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">142084</opensearch:totalResults>\n",
      "  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
      "  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">3</opensearch:itemsPerPage>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2509.15217v1</id>\n",
      "    <updated>2025-09-18T17:59:11Z</updated>\n",
      "    <published>2025-09-18T17:59:11Z</published>\n",
      "    <title>Generalizable Geometric Image Caption Synthesis</title>\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "Root tag: {http://www.w3.org/2005/Atom}feed\n",
      "Root attributes: {}\n",
      "\n",
      "XML structure:\n",
      "  0: {http://www.w3.org/2005/Atom}link\n",
      "  1: {http://www.w3.org/2005/Atom}title\n",
      "  2: {http://www.w3.org/2005/Atom}id\n",
      "  3: {http://www.w3.org/2005/Atom}updated\n",
      "  4: {http://a9.com/-/spec/opensearch/1.1/}totalResults\n",
      "  5: {http://a9.com/-/spec/opensearch/1.1/}startIndex\n",
      "  6: {http://a9.com/-/spec/opensearch/1.1/}itemsPerPage\n",
      "  7: {http://www.w3.org/2005/Atom}entry\n",
      "  8: {http://www.w3.org/2005/Atom}entry\n",
      "  9: {http://www.w3.org/2005/Atom}entry\n"
     ]
    }
   ],
   "source": [
    "# Look at the raw XML response\n",
    "print(\"Raw XML response (first 1000 characters):\")\n",
    "print(response.text[:1000])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Parse the XML\n",
    "root = ET.fromstring(response.content)\n",
    "print(f\"Root tag: {root.tag}\")\n",
    "print(f\"Root attributes: {root.attrib}\")\n",
    "\n",
    "# Show the structure\n",
    "print(\"\\nXML structure:\")\n",
    "for i, child in enumerate(root):\n",
    "    print(f\"  {i}: {child.tag}\")\n",
    "    if i > 10:  # Don't print too many\n",
    "        print(\"  ...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4272bf4-ac0a-4607-bf2b-138779e196ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results available: 142084\n",
      "Number of papers returned: 3\n",
      "\n",
      "==================================================\n",
      "FIRST PAPER DETAILS:\n",
      "==================================================\n",
      "{\n",
      "  \"id\": \"http://arxiv.org/abs/2509.15217v1\",\n",
      "  \"title\": \"Generalizable Geometric Image Caption Synthesis\",\n",
      "  \"summary\": \"Multimodal large language models have various practical applications that\\ndemand strong reasoning abilities. Despite recent advancements, these models\\nstill struggle to solve complex geometric problems. A key challenge stems from\\nthe lack of high-quality image-text pair datasets for understanding geometric\\nimages. Furthermore, most template-based data synthesis pipelines typically\\nfail to generalize to questions beyond their predefined templates. In this\\npaper, we bridge this gap by introducing a complementary process of\\nReinforcement Learning with Verifiable Rewards (RLVR) into the data generation\\npipeline. By adopting RLVR to refine captions for geometric images synthesized\\nfrom 50 basic geometric relations and using reward signals derived from\\nmathematical problem-solving tasks, our pipeline successfully captures the key\\nfeatures of geometry problem-solving. This enables better task generalization\\nand yields non-trivial improvements. Furthermore, even in out-of-distribution\\nscenarios, the generated dataset enhances the general reasoning capabilities of\\nmultimodal large language models, yielding accuracy improvements of\\n$2.8\\\\%\\\\text{-}4.8\\\\%$ in statistics, arithmetic, algebraic, and numerical tasks\\nwith non-geometric input images of MathVista and MathVerse, along with\\n$2.4\\\\%\\\\text{-}3.9\\\\%$ improvements in Art, Design, Tech, and Engineering tasks\\nin MMMU.\",\n",
      "  \"published\": \"2025-09-18T17:59:11Z\",\n",
      "  \"authors\": [\n",
      "    \"Yue Xin\",\n",
      "    \"Wenyuan Wang\",\n",
      "    \"Rui Pan\",\n",
      "    \"Ruida Wang\",\n",
      "    \"Howard Meng\",\n",
      "    \"Renjie Pi\",\n",
      "    \"Shizhe Diao\",\n",
      "    \"Tong Zhang\"\n",
      "  ],\n",
      "  \"categories\": [\n",
      "    \"cs.AI\",\n",
      "    \"cs.CV\",\n",
      "    \"cs.LG\"\n",
      "  ],\n",
      "  \"links\": {\n",
      "    \"alternate\": \"http://arxiv.org/abs/2509.15217v1\",\n",
      "    \"pdf\": \"http://arxiv.org/pdf/2509.15217v1\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Manual XML parsing to understand the structure\n",
    "namespaces = {\n",
    "    'atom': 'http://www.w3.org/2005/Atom',\n",
    "    'arxiv': 'http://arxiv.org/schemas/atom',\n",
    "    'opensearch': 'http://a9.com/-/spec/opensearch/1.1/'\n",
    "}\n",
    "\n",
    "# Get total results\n",
    "total_results = root.find('opensearch:totalResults', namespaces)\n",
    "if total_results is not None:\n",
    "    print(f\"Total results available: {total_results.text}\")\n",
    "\n",
    "# Extract paper entries\n",
    "entries = root.findall('atom:entry', namespaces)\n",
    "print(f\"Number of papers returned: {len(entries)}\")\n",
    "\n",
    "# Parse first paper in detail\n",
    "if entries:\n",
    "    first_paper = entries[0]\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FIRST PAPER DETAILS:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Extract all the key fields\n",
    "    paper_data = {}\n",
    "    \n",
    "    # ID and URLs\n",
    "    id_elem = first_paper.find('atom:id', namespaces)\n",
    "    paper_data['id'] = id_elem.text if id_elem is not None else \"N/A\"\n",
    "    \n",
    "    # Title\n",
    "    title_elem = first_paper.find('atom:title', namespaces)\n",
    "    paper_data['title'] = title_elem.text.strip() if title_elem is not None else \"N/A\"\n",
    "    \n",
    "    # Summary (abstract)\n",
    "    summary_elem = first_paper.find('atom:summary', namespaces)\n",
    "    paper_data['summary'] = summary_elem.text.strip() if summary_elem is not None else \"N/A\"\n",
    "    \n",
    "    # Published date\n",
    "    published_elem = first_paper.find('atom:published', namespaces)\n",
    "    paper_data['published'] = published_elem.text if published_elem is not None else \"N/A\"\n",
    "    \n",
    "    # Authors\n",
    "    authors = []\n",
    "    for author in first_paper.findall('atom:author', namespaces):\n",
    "        name_elem = author.find('atom:name', namespaces)\n",
    "        if name_elem is not None:\n",
    "            authors.append(name_elem.text)\n",
    "    paper_data['authors'] = authors\n",
    "    \n",
    "    # Categories\n",
    "    categories = []\n",
    "    for category in first_paper.findall('atom:category', namespaces):\n",
    "        term = category.get('term')\n",
    "        if term:\n",
    "            categories.append(term)\n",
    "    paper_data['categories'] = categories\n",
    "    \n",
    "    # Links (especially PDF)\n",
    "    links = {}\n",
    "    for link in first_paper.findall('atom:link', namespaces):\n",
    "        rel = link.get('rel', 'alternate')\n",
    "        title = link.get('title', rel)\n",
    "        href = link.get('href')\n",
    "        links[title] = href\n",
    "    paper_data['links'] = links\n",
    "    \n",
    "    # Print extracted data\n",
    "    print(json.dumps(paper_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cf9a4e-80dd-4d28-bde1-77c6c7af8fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using arxiv library for the same search...\n",
      "Fetching results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murph\\AppData\\Local\\Temp\\ipykernel_10620\\294774136.py:13: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  results = list(search.results())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 3 results\n",
      "\n",
      "==================================================\n",
      "FIRST PAPER USING ARXIV LIBRARY:\n",
      "==================================================\n",
      "{\n",
      "  \"arxiv_id\": \"2509.15217v1\",\n",
      "  \"title\": \"Generalizable Geometric Image Caption Synthesis\",\n",
      "  \"summary\": \"Multimodal large language models have various practical applications that\\ndemand strong reasoning abilities. Despite recent advancements, these models\\nstill struggle to solve complex geometric problems. A key challenge stems from\\nthe lack of high-quality image-text pair datasets for understanding geometric\\nimages. Furthermore, most template-based data synthesis pipelines typically\\nfail to generalize to questions beyond their predefined templates. In this\\npaper, we bridge this gap by introducing a complementary process of\\nReinforcement Learning with Verifiable Rewards (RLVR) into the data generation\\npipeline. By adopting RLVR to refine captions for geometric images synthesized\\nfrom 50 basic geometric relations and using reward signals derived from\\nmathematical problem-solving tasks, our pipeline successfully captures the key\\nfeatures of geometry problem-solving. This enables better task generalization\\nand yields non-trivial improvements. Furthermore, even in out-of-distribution\\nscenarios, the generated dataset enhances the general reasoning capabilities of\\nmultimodal large language models, yielding accuracy improvements of\\n$2.8\\\\%\\\\text{-}4.8\\\\%$ in statistics, arithmetic, algebraic, and numerical tasks\\nwith non-geometric input images of MathVista and MathVerse, along with\\n$2.4\\\\%\\\\text{-}3.9\\\\%$ improvements in Art, Design, Tech, and Engineering tasks\\nin MMMU.\",\n",
      "  \"published\": \"2025-09-18T17:59:11+00:00\",\n",
      "  \"updated\": \"2025-09-18T17:59:11+00:00\",\n",
      "  \"authors\": [\n",
      "    \"Yue Xin\",\n",
      "    \"Wenyuan Wang\",\n",
      "    \"Rui Pan\",\n",
      "    \"Ruida Wang\",\n",
      "    \"Howard Meng\",\n",
      "    \"Renjie Pi\",\n",
      "    \"Shizhe Diao\",\n",
      "    \"Tong Zhang\"\n",
      "  ],\n",
      "  \"primary_category\": \"cs.AI\",\n",
      "  \"categories\": [\n",
      "    \"cs.AI\",\n",
      "    \"cs.CV\",\n",
      "    \"cs.LG\"\n",
      "  ],\n",
      "  \"pdf_url\": \"http://arxiv.org/pdf/2509.15217v1\",\n",
      "  \"comment\": null,\n",
      "  \"journal_ref\": null,\n",
      "  \"doi\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Now let's use the arxiv library to do the same thing\n",
    "print(\"Using arxiv library for the same search...\")\n",
    "\n",
    "# Create a search\n",
    "search = arxiv.Search(\n",
    "    query=\"cat:cs.AI\",\n",
    "    max_results=3,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "    sort_order=arxiv.SortOrder.Descending\n",
    ")\n",
    "\n",
    "print(\"Fetching results...\")\n",
    "results = list(search.results())\n",
    "\n",
    "print(f\"Got {len(results)} results\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FIRST PAPER USING ARXIV LIBRARY:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if results:\n",
    "    paper = results[0]\n",
    "    \n",
    "    # Create clean dictionary\n",
    "    paper_dict = {\n",
    "        'arxiv_id': paper.entry_id.split('/')[-1],  # Extract ID from URL\n",
    "        'title': paper.title,\n",
    "        'summary': paper.summary,\n",
    "        'published': paper.published.isoformat(),\n",
    "        'updated': paper.updated.isoformat() if paper.updated else None,\n",
    "        'authors': [str(author) for author in paper.authors],\n",
    "        'primary_category': paper.primary_category,\n",
    "        'categories': paper.categories,\n",
    "        'pdf_url': paper.pdf_url,\n",
    "        'comment': paper.comment,\n",
    "        'journal_ref': paper.journal_ref,\n",
    "        'doi': paper.doi\n",
    "    }\n",
    "    \n",
    "    print(json.dumps(paper_dict, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "992c9445-f5e0-4f04-a8c7-31b1d825f096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SEARCH: Recent AI Papers\n",
      "DESCRIPTION: All AI papers\n",
      "QUERY: cat:cs.AI\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murph\\AppData\\Local\\Temp\\ipykernel_10620\\4096871734.py:40: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  results = list(search.results())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 results\n",
      "\n",
      "1. Generalizable Geometric Image Caption Synthesis\n",
      "   Authors: Yue Xin, Wenyuan Wang, Rui Pan\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.AI, cs.CV, cs.LG\n",
      "   Abstract (first 100 chars): Multimodal large language models have various practical applications that\n",
      "demand strong reasoning ab...\n",
      "\n",
      "2. Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation\n",
      "   Authors: Chen Si, Qianyi Wu, Chaitanya Amballa\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.SD, cs.AI, cs.LG\n",
      "   Abstract (first 100 chars): Realistic sound simulation plays a critical role in many applications. A key\n",
      "element in sound simula...\n",
      "\n",
      "============================================================\n",
      "SEARCH: Transformer Papers\n",
      "DESCRIPTION: Papers mentioning \"transformer\"\n",
      "QUERY: all:transformer\n",
      "============================================================\n",
      "Found 2 results\n",
      "\n",
      "1. Geometric Image Synchronization with Deep Watermarking\n",
      "   Authors: Pierre Fernandez, Tomáš Souček, Nikola Jovanović\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.CV\n",
      "   Abstract (first 100 chars): Synchronization is the task of estimating and inverting geometric\n",
      "transformations (e.g., crop, rotat...\n",
      "\n",
      "2. FlowRL: Matching Reward Distributions for LLM Reasoning\n",
      "   Authors: Xuekai Zhu, Daixuan Cheng, Dinghuai Zhang\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.LG, cs.AI, cs.CL\n",
      "   Abstract (first 100 chars): We propose FlowRL: matching the full reward distribution via flow balancing\n",
      "instead of maximizing re...\n",
      "\n",
      "============================================================\n",
      "SEARCH: Recent ML + Attention\n",
      "DESCRIPTION: ML papers about attention\n",
      "QUERY: cat:cs.LG AND all:attention\n",
      "============================================================\n",
      "Found 2 results\n",
      "\n",
      "1. Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers\n",
      "   Authors: Andrei Chertkov, Artem Basharin, Mikhail Saygin\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.LG\n",
      "   Abstract (first 100 chars): The growing demand for energy-efficient, high-performance AI systems has led\n",
      "to increased attention ...\n",
      "\n",
      "2. Communication Efficient Split Learning of ViTs with Attention-based Double Compression\n",
      "   Authors: Federico Alvetreti, Jary Pomponi, Paolo Di Lorenzo\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.LG, cs.AI, cs.CV\n",
      "   Abstract (first 100 chars): This paper proposes a novel communication-efficient Split Learning (SL)\n",
      "framework, named Attention-b...\n",
      "\n",
      "============================================================\n",
      "SEARCH: Recent Papers by Date\n",
      "DESCRIPTION: AI papers from last 7 days\n",
      "QUERY: cat:cs.AI AND submittedDate:[20250913 TO *]\n",
      "============================================================\n",
      "Found 0 results\n"
     ]
    }
   ],
   "source": [
    "# Let's try different types of searches\n",
    "search_queries = [\n",
    "    {\n",
    "        'name': 'Recent AI Papers',\n",
    "        'query': 'cat:cs.AI',\n",
    "        'description': 'All AI papers'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Transformer Papers',\n",
    "        'query': 'all:transformer',\n",
    "        'description': 'Papers mentioning \"transformer\"'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Recent ML + Attention',\n",
    "        'query': 'cat:cs.LG AND all:attention',\n",
    "        'description': 'ML papers about attention'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Recent Papers by Date',\n",
    "        'query': f'cat:cs.AI AND submittedDate:[{(datetime.now() - timedelta(days=7)).strftime(\"%Y%m%d\")} TO *]',\n",
    "        'description': 'AI papers from last 7 days'\n",
    "    }\n",
    "]\n",
    "\n",
    "for search_config in search_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SEARCH: {search_config['name']}\")\n",
    "    print(f\"DESCRIPTION: {search_config['description']}\")\n",
    "    print(f\"QUERY: {search_config['query']}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    try:\n",
    "        search = arxiv.Search(\n",
    "            query=search_config['query'],\n",
    "            max_results=2,\n",
    "            sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "            sort_order=arxiv.SortOrder.Descending\n",
    "        )\n",
    "        \n",
    "        results = list(search.results())\n",
    "        print(f\"Found {len(results)} results\")\n",
    "        \n",
    "        for i, paper in enumerate(results):\n",
    "            print(f\"\\n{i+1}. {paper.title}\")\n",
    "            print(f\"   Authors: {', '.join(str(author) for author in paper.authors[:3])}\")\n",
    "            print(f\"   Published: {paper.published.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"   Categories: {', '.join(paper.categories[:3])}\")\n",
    "            print(f\"   Abstract (first 100 chars): {paper.summary[:100]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error with search: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5d60c5-de43-47cf-ba44-8db7f13a918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing helper functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murph\\AppData\\Local\\Temp\\ipykernel_10620\\1930849373.py:19: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 papers:\n",
      "--------------------------------------------------------------------------------\n",
      "1. Generalizable Geometric Image Caption Synthesis\n",
      "   ID: 2509.15217v1\n",
      "   Authors: Yue Xin, Wenyuan Wang\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.AI, cs.CV, cs.LG\n",
      "\n",
      "2. Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation\n",
      "   ID: 2509.15210v1\n",
      "   Authors: Chen Si, Qianyi Wu\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.SD, cs.AI, cs.LG\n",
      "\n",
      "3. FlowRL: Matching Reward Distributions for LLM Reasoning\n",
      "   ID: 2509.15207v1\n",
      "   Authors: Xuekai Zhu, Daixuan Cheng\n",
      "   Published: 2025-09-18\n",
      "   Categories: cs.LG, cs.AI, cs.CL\n",
      "\n",
      "\n",
      "Saved 3 papers to data/sample_papers.json\n"
     ]
    }
   ],
   "source": [
    "def search_arxiv_papers(query, max_results=5, sort_by='submittedDate'):\n",
    "    \"\"\"\n",
    "    Helper function to search arXiv and return clean data\n",
    "    \"\"\"\n",
    "    sort_criterion = {\n",
    "        'submittedDate': arxiv.SortCriterion.SubmittedDate,\n",
    "        'relevance': arxiv.SortCriterion.Relevance,\n",
    "        'lastUpdatedDate': arxiv.SortCriterion.LastUpdatedDate\n",
    "    }.get(sort_by, arxiv.SortCriterion.SubmittedDate)\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=sort_criterion,\n",
    "        sort_order=arxiv.SortOrder.Descending\n",
    "    )\n",
    "    \n",
    "    papers = []\n",
    "    for result in search.results():\n",
    "        paper = {\n",
    "            'arxiv_id': result.entry_id.split('/')[-1],\n",
    "            'title': result.title,\n",
    "            'summary': result.summary,\n",
    "            'published': result.published.isoformat(),\n",
    "            'authors': [str(author) for author in result.authors],\n",
    "            'categories': result.categories,\n",
    "            'pdf_url': result.pdf_url\n",
    "        }\n",
    "        papers.append(paper)\n",
    "    \n",
    "    return papers\n",
    "\n",
    "def print_papers_summary(papers):\n",
    "    \"\"\"\n",
    "    Pretty print papers summary\n",
    "    \"\"\"\n",
    "    print(f\"Found {len(papers)} papers:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, paper in enumerate(papers, 1):\n",
    "        print(f\"{i}. {paper['title']}\")\n",
    "        print(f\"   ID: {paper['arxiv_id']}\")\n",
    "        print(f\"   Authors: {', '.join(paper['authors'][:2])}\")\n",
    "        print(f\"   Published: {paper['published'][:10]}\")\n",
    "        print(f\"   Categories: {', '.join(paper['categories'][:3])}\")\n",
    "        print()\n",
    "\n",
    "# Test the helper functions\n",
    "print(\"Testing helper functions...\")\n",
    "papers = search_arxiv_papers(\"cat:cs.AI\", max_results=3)\n",
    "print_papers_summary(papers)\n",
    "\n",
    "# Save to JSON file for later use\n",
    "with open('../data/sample_papers.json', 'w') as f:\n",
    "    json.dump(papers, f, indent=2)\n",
    "    \n",
    "print(f\"\\nSaved {len(papers)} papers to data/sample_papers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58bd6585-33c8-4a22-be17-74efdaa04ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: cat:cs.AI\n",
      "Adding 1s delay to respect rate limits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murph\\AppData\\Local\\Temp\\ipykernel_10620\\2664751449.py:19: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  results = list(search.results())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully retrieved 2 papers\n",
      "Query 'cat:cs.AI' returned 2 papers\n",
      "\n",
      "Searching for: invalid:query:format\n",
      "Adding 1s delay to respect rate limits...\n",
      "✅ Successfully retrieved 0 papers\n",
      "Query 'invalid:query:format' returned 0 papers\n",
      "\n",
      "Searching for: cat:cs.LG AND all:neural\n",
      "Adding 1s delay to respect rate limits...\n",
      "✅ Successfully retrieved 2 papers\n",
      "Query 'cat:cs.LG AND all:neural' returned 2 papers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def safe_arxiv_search(query, max_results=5, delay=1):\n",
    "    \"\"\"\n",
    "    Search with error handling and rate limiting\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Searching for: {query}\")\n",
    "        print(f\"Adding {delay}s delay to respect rate limits...\")\n",
    "        time.sleep(delay)\n",
    "        \n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "            sort_order=arxiv.SortOrder.Descending\n",
    "        )\n",
    "        \n",
    "        results = list(search.results())\n",
    "        print(f\"✅ Successfully retrieved {len(results)} papers\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test error handling\n",
    "test_queries = [\n",
    "    \"cat:cs.AI\",\n",
    "    \"invalid:query:format\",  # This might cause an error\n",
    "    \"cat:cs.LG AND all:neural\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    papers = safe_arxiv_search(query, max_results=2, delay=1)\n",
    "    print(f\"Query '{query}' returned {len(papers)} papers\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7a82e9-83b0-4458-afb6-889a095cc6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat:cs.LG AND all:neural'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b199eb36-c327-43d7-852d-c8c7a44c223e",
   "metadata": {},
   "source": [
    "# Where to search for your keywords:\n",
    "\n",
    "* `all:transformer`     # Search title, abstract, comments, AND author names\n",
    "* `ti:attention`        # Search ONLY in title  \n",
    "* `abs:neural`          # Search ONLY in abstract\n",
    "* `co:preliminary`      # Search ONLY in comments\n",
    "* `au:lecun`           # Search ONLY in author names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee6baa-8c9b-4ffa-b9da-94b4ae801b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
